<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Geeta Chandra Raju, Bethala</title>

    <meta name="author" content="Geeta Chandra Raju, Bethala">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Geeta Chandra Raju, Bethala
                </p>

                
                <p>
                  I am a Research Engineer at New York University Abu Dhabi, working in the <a href="https://nyuair.github.io/website/" target="_blank">Embodied AI and Robotics Lab (AIR Lab)</a> (NYU) and the <a href="https://nyuad.nyu.edu/en/research/faculty-labs-and-projects/center-for-artificial-intelligence-and-robotics.html" target="_blank">Center for Artificial Intelligence and Robotics (CAIR)</a> at NYUAD, working with <a href="https://nyuad.nyu.edu/en/academics/divisions/engineering/faculty/yi-fang.html" target="_blank">Prof Yi Fang</a>. I am also collaborating with <a href="https://eye.hms.harvard.edu/mengyuwang" target="_blank">Prof. Mengyu Wang</a> on embodied AI projects at the <a href="https://wang.hms.harvard.edu/" target="_blank">Harvard AI and Robotics Lab</a>.
                </p>
                <p>
                  I earned my <b>M.S. in Mechatronics and Robotics</b> at <b>New York University</b> Tandon School of Engineering, supported by the Tandon Merit Scholarship and a Andhra Pradesh State Government Fellowship. I completed my thesis with Prof. Yi Fang and also served as a Research Assistant in the <a href="https://ai4ce.github.io/" target="_blank">Ai4CE Lab</a> with Prof. <a href="https://engineering.nyu.edu/faculty/chen-feng" target="_blank">Chen Feng</a> and in the <a href="https://mechatronics.engineering.nyu.edu/" target="_blank">MCRL</a> with Prof. <a href="https://engineering.nyu.edu/faculty/vikram-kapila" target="_blank">Vikram Kapila</a>. I hold a <b>B.Tech in Mechanical Engineering</b> from <b>Acharya Nagarjuna University</b>, Andhra Pradesh, India. After earning my bachelor's degree, I helped develop telepresence conference and inspection robots at a <a href="https://racchabanda.com/" target="_blank">startup</a>, and following my master's I worked as a Research Scientist at NYU before joining NYUAD.
                </p>


                <p style="text-align:center">
                  <a href="mailto:gb2643@nyu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=FlJ6woUAAAAJ&hl=en" target="_blank">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/bethalageetachandraraju?tab=repositories" target="_blank">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.instagram.com/geetachandraraju/" title="For cool robot videos and poetry" target="_blank">Instagram</a> 
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/bgcr.jpg"><img style="width:50%;max-width:50%;object-fit: cover;" alt="profile photo" src="images/bgcr.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research centers on embodied AI and physical intelligence, with a special focus on intuitive human-robot collaboration. I aim to develop adaptive robotic systems—especially humanoids—that seamlessly interact with people in dynamic, real-world environments.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="h2_compact_stop()" onmouseover="h2_compact_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <img src='data/h2compact.gif' autoplay loop>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2505.17627" target="_blank">
          <span class="papertitle">H2-COMPACT: Human-Humanoid Co-Manipulation via Adaptive Contact Trajectory Policies</span>
        </a>
        <br>
        <strong>Geeta Chandra Raju. Bethala</strong>,
        H. Huang,
        N. Pudasaini,
        AM Ali,
        S. Yuan,
        C. Wen,
        A. Tzes,
        Y. Fang
        <br>
        <em>IEEE-RAS 24th International Conference on Humanoid Robots (Humanoids)</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2505.17627" target="_blank">arXiv</a> /
        <a href="https://h2compact.github.io/h2compact/" target="_blank">Webpage</a> 
        <!-- <a href="https://github.com/h2compact/h2compact" target="_blank">Code</a> -->
        <p></p>
        <p>
          A legged humanoid that uses haptic cues to understand human intent and cooperatively carry loads with adaptive, stable locomotion.
        </p>
      </td>
    </tr>

    
    <tr onmouseout="wavelet_policy_stop()" onmouseover="wavelet_policy_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <img src='images/wavelet.png'>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2507.04331">
          <span class="papertitle">Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks</span>
        </a>
        <br>
        H. Huang,
        S. Yuan,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        C. Wen,
        A. Tzes,
        Y. Fang
        <br>
        <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2507.04331">arXiv</a>
        <p></p>
        <p>
          A wavelet-based policy learning framework that enhances decision-making in complex, long-horizon tasks by analyzing observations across multiple scales for precise and reliable action planning.
        </p>
      </td>
    </tr>


    
    <tr onmouseout="social_nav_stop()" onmouseover="social_nav_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <video src='data/hallway_passive_on_your_left_new.mp4' autoplay loop muted>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2409.04965">
          <span class="papertitle">Socially-Aware Robot Navigation Enhanced by Bidirectional Natural Language Conversations Using Large Language Models</span>
        </a>
        <br>
        C. Wen,
        Y. Liu,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        S. Yuan,
        H. Huang,
        Y. Hao,
        M. Wang,
        YS Liu
        <br>
        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2409.04965">arXiv</a> /
        <a href="https://hsacllm.github.io/" target="_blank">Webpage</a> /
        <a href="https://github.com/bethalageetachandraraju/llm-social-navigation-bot" target="_blank">Code</a>
        <p></p>
        <p>
          Socially aware robot navigation framework that combines deep reinforcement learning with language interaction, enabling robots to communicate with pedestrians and navigate safely in dynamic environments.
        </p>
      </td>
    </tr>



    <tr onmouseout="embodied_chain_stop()" onmouseover="embodied_chain_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <img src='images/embodied.png'>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2504.09532" target="_blank">
          <span class="papertitle">Embodied Chain of Action Reasoning with Multi-Modal Foundation Model for Humanoid Loco-manipulation</span>
        </a>
        <br>
        Y. Hao*,
        <strong>Geeta Chandra Raju. Bethala*</strong>,
        N. Pudasaini*,
        H. Huang,
        S. Yuan,
        C. Wen,
        B. Huang
        <br>
        <em>arXiv preprint arXiv:2504.09532</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2504.09532" target="_blank">arXiv</a>
        <p></p>
        <p>
          A foundation-model framework that lets humanoid robots understand text instructions and perform complex loco-manipulation through multi-step reasoning.
        </p>
      </td>
    </tr>

    <tr onmouseout="llm_nav_stop()" onmouseover="llm_nav_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <img src='images/nav_llm.png'>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2402.09546" target="_blank">
          <span class="papertitle">How secure are large language models (LLMs) for navigation in urban environments?</span>
        </a>
        <br>
        C. Wen,
        J. Liang,
        S. Yuan,
        H. Huang,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        YS Liu,
        M. Wang,
        A. Tzes
        <br>
        <em>Under Review (Journal)</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2402.09546" target="_blank">arXiv</a>
        <p></p>
        <p>
          This work exposes vulnerabilities in LLM-based robot navigation through novel prompt attacks and proposes initial defenses to enhance the security of autonomous navigation systems.
        </p>
      </td>
    </tr>

    <tr onmouseout="hierarchical_scoring_stop()" onmouseover="hierarchical_scoring_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <video src='data/neurips.mp4' autoplay loop muted>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2506.07338" target="_blank">
          <span class="papertitle">Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation</span>
        </a>
        <br>
        Y. Deng,
        S. Yuan,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        A. Tzes,
        YS Liu,
        Y. Fang
        <br>
        <em>Under Review</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2506.07338" target="_blank">arXiv</a> /
        <a href="data/IGN_B1 (1).mp4"> Video</a>
      
        <p></p>
        <p>
          Advanced instance image-goal navigation using hierarchical scoring and 3D Gaussian splatting for precise target localization.
        </p>
      </td>
    </tr>



    <tr onmouseout="mapbert_stop()" onmouseover="mapbert_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
        <div class="one">
          <img src='images/bertmap.png'>
        </div>
      </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2506.07350" target="_blank">
          <span class="papertitle">MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation</span>
        </a>
        <br>
        Y. Deng,
        S. Yuan,
        C. Wen,
        H. Huang,
        A. Tzes,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        Y. Fang
        <br>
        <em>arXiv preprint arXiv:2506.07350</em>
        <br>
        <a href="https://arxiv.org/abs/2506.07350" target="_blank">arXiv</a>
        <!-- <a href="data/mapbert.mp4" target="_blank">Video</a> -->
        <p></p>
        <p>
          MapBERT is a transformer-based framework that predicts unobserved indoor regions from partial semantic maps, enabling spatially aware and efficient navigation for embodied agents.
        </p>
      </td>
    </tr>
	


    <tr onmouseout="retrospective_framework_stop()" onmouseover="retrospective_framework_start()" class="paper-row">
      <td style="padding:8px;width:25%;vertical-align:top">
      <div class="one">
          <img src='images/icara.png'>
      </div>
    </td>
      <td style="padding:8px;width:75%;vertical-align:top;padding-left:50px">
        <a href="https://arxiv.org/abs/2502.11227" target="_blank">
          <span class="papertitle">Integrating Retrospective Framework in Multi-Robot Collaboration</span>
      </a>
      <br>
        J. Liang,
        H. Huang,
        Y. Hao,
        <strong>Geeta Chandra Raju. Bethala</strong>,
        C. Wen,
        Y. Fang
        <br>
        <em>International Conference on Automation, Robotics, and Applications (ICARA)</em>, 2025
        <br>
        <a href="https://arxiv.org/abs/2502.11227" target="_blank">arXiv</a>
      <p></p>
      <p>
          A retrospective actor-critic framework for multi-robot collaboration that enhances real-time decision-making and adaptability in dynamic environments.
      </p>
    </td>
  </tr>


            
          </tbody></table>
          
          <!-- Cool Robot Videos Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Cool Robot Videos</h2>
                <p>
                  Check out some amazing robot demonstrations and research highlights!
      </p>
    </td>
  </tr>
          </tbody></table>
          
          <div class="video-slider-container">
            <div class="video-slider" id="videoSlider">
              <!-- Row 1 -->
              <div class="video-row" id="row1">

                <div class="video-item">
                  <video src="data/video_bar/social_nav_1.mp4" autoplay loop muted>
    Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Social Navigation 1</p>
                  <p class="video-description">Socially-aware robot navigation with human interaction and path planning.</p>
    </div>
                <div class="video-item">
                  <video src="data/video_bar/social_nav_2.mp4" autoplay loop muted>
          Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Social Navigation 2</p>
                  <p class="video-description">Advanced social navigation demonstrating human-aware robot behavior.</p>
        </div>

        <div class="video-item">
          <img src="data/video_bar/human_mimic.gif" alt="Human Mimicry" style="width:100%; max-width:240px; max-height:180px; border-radius:6px; display:block; margin:0 auto;">
          <p class="video-caption">Human Mimicry</p>
          <p class="video-description">Humanoid robot mimicking human movements and gestures for natural interaction.</p>
  </div>
                <div class="video-item">
                  <video src="data/video_bar/stand_pick_place.mp4" autoplay loop muted>
            Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Stand & Pick-Place</p>
                  <p class="video-description">Humanoid robot standing up and performing precise pick-and-place manipulation tasks.</p>
          </div>
                <div class="video-item">
                  <video src="data/video_bar/g1_kungfu_REC.mp4" autoplay loop muted>
            Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Kung Fu Motion</p>
                  <p class="video-description">Dynamic martial arts movements demonstrating advanced humanoid locomotion control.</p>
          </div>
                <div class="video-item">
                  <video src="data/video_bar/g1_ik.mp4" autoplay loop muted>
            Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Inverse Kinematics</p>
                  <p class="video-description">Advanced inverse kinematics control for precise humanoid arm positioning.</p>
          </div>
                <div class="video-item">
                  <video src="data/video_bar/force_walk_hand.mp4" autoplay loop muted>
            Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Force Walking</p>
                  <p class="video-description">Force-controlled walking with hand support for stable humanoid locomotion.</p>
          </div>
                <div class="video-item">
                  <video src="data/video_bar/yolo_nav.mp4" autoplay loop muted>
        Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">YOLO Navigation</p>
                  <p class="video-description">Object detection-based navigation using YOLO for autonomous robot movement.</p>
      </div>
                <div class="video-item">
                  <video src="data/video_bar/nav_b1.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Navigation B1</p>
                  <p class="video-description">Advanced navigation system demonstrating path planning and obstacle avoidance.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/navdp.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Navigation DP</p>
                  <p class="video-description">Dynamic programming-based navigation for optimal path finding in complex environments.</p>
                </div>
                
                <div class="video-item">
                  <video src="data/video_bar/screwdriver_manip.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Tool Manipulation</p>
                  <p class="video-description">Precise screwdriver manipulation demonstrating fine motor control and tool usage.</p>
                </div>
                </div>

              <!-- Row 2 -->
              <div class="video-row" id="row2">
                <div class="video-item">
                  <video src="data/video_bar/hand_teleop.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Hand Teleoperation</p>
                  <p class="video-description">Hand-based teleoperation system for intuitive robot control and manipulation.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/vr_teleop.mp4" autoplay loop muted style="width:100%; max-width:240px; max-height:180px; border-radius:6px; display:block; margin:0 auto;">
                    Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">VR Teleoperation</p>
                  <p class="video-description">Virtual reality-based teleoperation for immersive robot control and training.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/act_can.mp4" autoplay loop muted style="width:100%; max-width:240px; max-height:180px; border-radius:6px; display:block; margin:0 auto;">
                    Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Can Manipulation</p>
                  <p class="video-description">Robotic manipulation of cylindrical objects demonstrating adaptive grasping strategies.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/sitting_act_tele.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Sitting Teleoperation</p>
                  <p class="video-description">Teleoperated sitting and standing transitions for humanoid robot control.</p>
                </div>
                <div class="video-item">
                  <img src="data/video_bar/h1_Doing_squats0.gif" alt="h1_Doing_squats0" style="width:100%; max-width:240px; max-height:180px; border-radius:6px; display:block; margin:0 auto;">
                  <p class="video-caption">Squat Exercise</p>
                  <p class="video-description">Humanoid robot performing squat exercises with proper form and balance control.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/H1_realrobot_foottap_dance.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Foot Tap Dance</p>
                  <p class="video-description">Humanoid robot performing rhythmic foot tap dance movements with coordination.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/tita.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Tita Robot</p>
                  <p class="video-description">Specialized robot demonstration showcasing unique locomotion and manipulation capabilities.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/wham.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">WHAM Robot</p>
                  <p class="video-description">Whole-body humanoid robot demonstrating complex multi-limb coordination tasks.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/bottle_pick - Made with Clipchamp.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Bottle Pick</p>
                  <p class="video-description">Precise bottle picking and manipulation using advanced grasping algorithms.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/pick_place.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Pick & Place</p>
                  <p class="video-description">Robotic pick-and-place operations with object recognition and precise manipulation.</p>
                </div>
                <div class="video-item">
                  <video src="data/video_bar/expo_humaniod_dog_play.mp4" autoplay loop muted>
                  Your browser does not support the video tag.
                  </video>
                  <p class="video-caption">Humanoid-Dog Play</p>
                  <p class="video-description">Humanoid robot interacting and playing with a robotic dog demonstrating social robotics.</p>
                </div>
                </div>
                </div>
            
            <!-- Manual Navigation Buttons -->
            <div class="video-nav-buttons">
              <button class="video-nav-btn" onclick="slideVideos('left')">← Previous</button>
              <button class="video-nav-btn" onclick="slideVideos('right')">Next →</button>
                </div>
                </div>

          <script>
            let currentPosition = 0;
            const videoWidth = 280; // Width of each video item
            const gap = 15; // Gap between videos
            const step = videoWidth + gap; // Distance to move for one video
            const videosPerRow = 11;
            const visibleVideos = 4;
            const maxPosition = (videosPerRow - visibleVideos) * step;
            
            function slideVideos(direction) {
              const row1 = document.getElementById('row1');
              const row2 = document.getElementById('row2');
              
              // Add smooth transition for manual navigation
              row1.style.transition = 'transform 2s ease-in-out';
              row2.style.transition = 'transform 2s ease-in-out';
              
              if (direction === 'left') {
                currentPosition += step;
                if (currentPosition > 0) {
                  currentPosition = -maxPosition;
                }
              } else {
                currentPosition -= step;
                if (currentPosition < -maxPosition) {
                  currentPosition = 0;
                }
              }
              
              row1.style.transform = `translateX(${currentPosition}px)`;
              row2.style.transform = `translateX(${currentPosition}px)`;
            }
            
            // Auto-sliding functionality
            setInterval(() => {
              slideVideos('right');
            }, 10000);
                </script>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website <a href="https://github.com/jonbarron/jonbarron_website" target="_blank">source code</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
